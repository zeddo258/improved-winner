import pyaudio
import requests
import tkinter.font as tkFont
import ollama
import usb.core
import usb.util
from MeloTTS.melo.api import TTS
import pygame
from usb_4_mic_array.tuning import Tuning
import tkinter as tk
import numpy as np
import threading
import os
import json


dev = usb.core.find(idVendor=0x2886, idProduct=0x0018)
Mic_tuning = ''
if dev:
    Mic_tuning = Tuning(dev)

# API endpoint URL
URL = "http://localhost:8080/upload-audio/"
URL_OLLAMA = "http://localhost:11435/api/chat"
RESPEAKER_RATE = 16000
RESPEAKER_CHANNELS = 1
RESPEAKER_WIDTH = 2
RESPEAKER_INDEX = 1 
CHUNK = 1024
RECORD_SECONDS = 2
MAX_SILENCE_FRAMES = 30


p = pyaudio.PyAudio()

  
def bytes_to_text(audio_bytes: bytes):
    files = {'file': ('microphone_audio.wav', audio_bytes, 'audio/wav')}
    response = requests.post(URL, files=files)
    if response.status_code == 200:
        result = response.json().get("result", "")
        print(result)
        return result
    else:
        print(f"Error: {response.status_code}")
        return ""

convo = []
def stream_response(prompt):
    convo.append({'role': 'user', 'content':prompt})
    response = ''
    stream = ollama.chat(model='llama3.1:70b', messages=convo, stream=True)
    print('\nASSISSTANT:')

    for chunk in stream:
        content = chunk['message']['content']
        response += content
        print(content, end='', flush=True)

    print('\n')
    convo.append({'role':'assisstant', 'content':response})


def start_listening(stream):
    print("Listening...")

    frames = []
    silence_frames = 0

    while silence_frames < MAX_SILENCE_FRAMES:
        data = stream.read(CHUNK)
        frames.append(data)

        if Mic_tuning.is_voice():  
            silence_frames = 0 
        else:
            silence_frames += 1  

    audio_bytes = b''.join(frames)
        
    # Convert audio to text using the server
    transcribed_text = bytes_to_text(audio_bytes)
    return transcribed_text


class ChatbotApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Llama 3.1")

        self.root.geometry("800x600") 
        font_style = tkFont.Font(family="Microsoft YaHei", size=16)
 
        # å¢åŠ å°è©±æ¡†çš„å¤§å°ä¸¦è¨­ç½®å­—é«”
        self.text_area = tk.Text(root, height=30, width=80, font=font_style)  # è¨­ç½®å­—é«”å¤§å°
        self.text_area.pack(expand=True, fill=tk.BOTH)  # ä½¿ç”¨expandå’Œfillä½¿å°è©±æ¡†å¡«å……æ•´å€‹çª—å£

        # éº¥å…‹é¢¨æŒ‰éˆ•

        self.mic_button = tk.Button(root, text="ğŸ¤ é»æ“Šèªªè©±", font=font_style, width=20, height=2, command=self.on_mic_click)  # è¨­ç½®æŒ‰éˆ•å¤§å°
        self.mic_button.pack(pady=20)  # ä½¿ç”¨ pady å¢åŠ ä¸Šä¸‹é–“è·
        self.counter = 0
        # å„²å­˜å°è©±ç´€éŒ„
        system_prompt = "ä½ æ‰€åœ¨åœ°å€æ˜¯å°ç£,ä½ ä½¿ç”¨ç¹é«”ä¸­æ–‡å°è©±."
        self.convo = [{"role": "system", "content":system_prompt}]

       
    def on_mic_click(self):
        # æŒ‰ä¸‹æŒ‰éˆ•æ™‚ï¼Œå•Ÿå‹•éŒ„éŸ³ä¸¦é€²è¡Œè™•ç†
        threading.Thread(target=self.listen_and_process).start()

    def listen_and_process(self):
        if ( self.counter == 0 ):
            first_prompt = f"""ä½ æ˜¯<speaker>,æˆ‘æ˜¯<listener>. ç¾åœ¨<speaker>æ˜¯[æœ‹å‹],æä¾›å¹«åŠ©å’Œè†è½å°æ–¹ç…©æƒ±å’Œçµ¦å°æ–¹å»ºè­°.  ç†è§£<listener>çš„ç”Ÿæ´»å¤§å°äº‹,æœªä¾†è¦åŠƒ,èª²æ¥­å•é¡Œ,æ„Ÿæƒ…å•é¡Œ,æ—…éŠç¶“é©—,ç¾é£Ÿ,ç¶“é©—åˆ†äº«,å„ç¨®æ„Ÿæƒ³,æœ‰è¶£çš„æ•…äº‹,å¹»æƒ³ã€‚å›æ‡‰<listener>æå‡ºçš„å•é¡Œ,è‹¥ç„¡æ³•è§£ç­”<listener>çš„å•é¡Œï¼Œå°±è«‹<listener>å†æ›´å…·é«”èªªæ˜. è«‹ç”¨å£èªåŒ–çš„èªè¨€ï¼Œèˆ‡<listener>å°è©±,ç†è§£å°è©±å…§å®¹. ä»¥<speaker>çš„è§’è‰²æ›ä½åŒç†â€œlistenerâ€. <speaker>çš„å›æ‡‰éœ€è¦æ’é™¤éåº¦ç©æ¥µåŠéåº¦æ¨‚è§€ç”¨è©. ä¾[æœ‹å‹]çš„è§’åº¦,ä½¿ç”¨500å­—ä»¥å…§çš„å›æ‡‰,ä»¥æ”¯æŒå‹å›æ‡‰æ–¹å¼å›è¦†<listener>."""
            self.convo.append({'role': 'user', 'content': first_prompt})

        # é–‹å§‹éŒ„éŸ³ï¼Œä¸¦è™•ç†è½‰æ›å’Œå›æ‡‰
        stream = p.open(
            rate=RESPEAKER_RATE,
            format=p.get_format_from_width(RESPEAKER_WIDTH),
            channels=RESPEAKER_CHANNELS,
            input=True,
            input_device_index=RESPEAKER_INDEX,
        )
        
        # å‘¼å«éŒ„éŸ³åŠè™•ç†å‡½æ•¸
        self.update_conversation("Listening...\n")  # UIæ›´æ–°ç‚ºæ­£åœ¨è½
        transcribed_text = start_listening(stream)  # è¿”å›è½‰éŒ„æ–‡æœ¬
        stream.stop_stream()
        stream.close()

        if "None" not in transcribed_text:
            # æ›´æ–°ç”¨æˆ¶æå•
            self.update_conversation(f"ä½ : {transcribed_text}\n")
            # å‘¼å«chatbotæ¨¡å‹è™•ç†å›æ‡‰
            self.process_response(transcribed_text)
    
    def update_conversation(self, message):
        self.text_area.insert(tk.END, f"{message}")
        self.text_area.see(tk.END)  # è‡ªå‹•æ»¾å‹•åˆ°æœ€æ–°å°è©±

    def process_response(self, prompt):
        self.convo.append({'role': 'user', 'content': prompt})
        self.counter += 1
        response = ''
        stream = requests.post(
            url=URL_OLLAMA,
            json= {
                "model":'llama3.1:70b', 
                "messages":self.convo, 
                "stream":True,
            }
        )
        
        self.update_conversation("æ©Ÿå™¨äºº: ") 
        for chunk in stream.iter_lines():
            body = json.loads(chunk)
            if "error" in body:
                raise Exception(body["error"])
            if body.get("done") is False:
                message = body.get("message", "")
                content = message.get("content", "")
                response += content
            self.update_conversation(content)

        self.update_conversation("\n")
        self.text_to_speech(response)
        self.convo.append({'role': 'assistant', 'content': response})

    def text_to_speech(self, text):

        # Speed is adjustable
        speed = 0.8
        device = 'cuda:0'

        model = TTS(language='ZH', device=device)
        speaker_ids = model.hps.data.spk2id

        output_path = 'zh.wav'
        model.tts_to_file(text, speaker_ids['ZH'], output_path, speed=speed)

        # ä½¿ç”¨ pygame æ’­æ”¾éŸ³é »
        pygame.mixer.init()
        pygame.mixer.music.load(output_path)
        pygame.mixer.music.play()

        # ç­‰å¾…éŸ³é »æ’­æ”¾å®Œç•¢
        while pygame.mixer.music.get_busy():
            continue
        # åœæ­¢ä¸¦é€€å‡º pygame.mixer

        pygame.mixer.music.stop()
        pygame.mixer.quit()
        # åˆªé™¤éŸ³é »æ–‡ä»¶
        os.remove(output_path)

if __name__ == "__main__":
    root = tk.Tk()
    app = ChatbotApp(root)
    root.mainloop()
